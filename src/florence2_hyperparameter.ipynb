{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebd1949-0664-45f3-b252-835831cd12af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98925a3af544fd7aa671723bb43b971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247e8e74e2754cb694d885dbdd921038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd158857ab6e4f358463c6831bf46637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[I 2025-05-17 08:54:30,023] A new study created in memory with name: no-name-76498728-bf5a-4c51-952f-1d81b0e27549\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▃▃▅▃▂▄▅▃▃▂▄▂▃▅▃▄▄▄▂▄█▂▅▃▁▂▁▄▄▄▅▃▁▃▆▄▄</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▇▄▅▅█▅▆▅▇▆▄▄▅▄▃▃▇▅▅▆▃▄▂▂▃▄▅▂▅▁▅▅▆▅▃▄▅▄▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>0.99698</td></tr><tr><td>train/global_step</td><td>660</td></tr><tr><td>train/grad_norm</td><td>19.8411</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8912</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_0</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/cculfolp' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/cculfolp</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_084711-cculfolp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_085430-l80mmht5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l80mmht5' target=\"_blank\">hparam_trial_0</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l80mmht5' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l80mmht5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>1.884400</td>\n",
       "      <td>2.401741</td>\n",
       "      <td>0.284204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▁▁▂▂▄▂▃▂▆▄▃▄▄▆▅▃▃▇▄▅█▄▁▆▅▁▂▃▅▄▄▆▃▁▄▇▅▅</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>▄▃▅▄▆▅▇▇▆▇▇▄▅▃▄▂▇▄▂▃▅▁▅▃▄▃▅▅▂▄▄▆▄▆▅▁▄▆█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.40174</td></tr><tr><td>eval/rougeL</td><td>0.2842</td></tr><tr><td>eval/runtime</td><td>24.4172</td></tr><tr><td>eval/samples_per_second</td><td>6.061</td></tr><tr><td>eval/steps_per_second</td><td>3.031</td></tr><tr><td>total_flos</td><td>23362239693936.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>18.33407</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8844</td></tr><tr><td>train_loss</td><td>2.33973</td></tr><tr><td>train_runtime</td><td>240.4352</td></tr><tr><td>train_samples_per_second</td><td>5.507</td></tr><tr><td>train_steps_per_second</td><td>2.753</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_0</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l80mmht5' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l80mmht5</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_085430-l80mmht5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:00:16,182] Trial 0 finished with value: 0.28420393001275346 and parameters: {'learning_rate': 5.611516415334504e-06, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.005808361216819946, 'lora_r': 4, 'lora_alpha': 16, 'lora_dropout': 0.06370173320348284}. Best is trial 0 with value: 0.28420393001275346.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_090016-cyrkseow</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/cyrkseow' target=\"_blank\">hparam_trial_1</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/cyrkseow' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/cyrkseow</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>2.452400</td>\n",
       "      <td>2.989171</td>\n",
       "      <td>0.117415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 331 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▂▅█▁▄▅▂▃▆▄▇▃▅▁▃▅▃▆█▄▃▂▂▅▁▃▅▅▄▂▅▄▄</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▅▃▅▅▄▆▆▄▅▃▄▂▅▂▅▅▃▅▃▁▅▁▃▄▄▁▇▇▃▅▅█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.98917</td></tr><tr><td>eval/rougeL</td><td>0.11742</td></tr><tr><td>eval/runtime</td><td>17.378</td></tr><tr><td>eval/samples_per_second</td><td>8.516</td></tr><tr><td>eval/steps_per_second</td><td>2.129</td></tr><tr><td>total_flos</td><td>26495539862400.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>4.73576</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.4524</td></tr><tr><td>train_loss</td><td>2.80179</td></tr><tr><td>train_runtime</td><td>206.7788</td></tr><tr><td>train_samples_per_second</td><td>6.403</td></tr><tr><td>train_steps_per_second</td><td>1.601</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_1</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/cyrkseow' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/cyrkseow</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_090016-cyrkseow/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:05:23,421] Trial 1 finished with value: 0.117415161900456 and parameters: {'learning_rate': 2.310201887845294e-06, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 1, 'weight_decay': 0.06118528947223795, 'lora_r': 16, 'lora_alpha': 16, 'lora_dropout': 0.15427033152408348}. Best is trial 0 with value: 0.28420393001275346.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_090523-vy36axc6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/vy36axc6' target=\"_blank\">hparam_trial_2</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/vy36axc6' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/vy36axc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [83/83 02:59, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:10:06,496] Trial 2 pruned. Trial was pruned at step 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▁▄▄▅▇▃█▇</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>▆█▃▆▁▁▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.93404</td></tr><tr><td>eval/rougeL</td><td>0.11448</td></tr><tr><td>eval/runtime</td><td>17.3426</td></tr><tr><td>eval/samples_per_second</td><td>8.534</td></tr><tr><td>eval/steps_per_second</td><td>2.133</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>83</td></tr><tr><td>train/grad_norm</td><td>3.35293</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.993</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_2</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/vy36axc6' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/vy36axc6</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_090523-vy36axc6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_091006-g0d8m4bg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/g0d8m4bg' target=\"_blank\">hparam_trial_3</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/g0d8m4bg' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/g0d8m4bg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>2.290500</td>\n",
       "      <td>2.915723</td>\n",
       "      <td>0.146858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▄▄▄▃▄▄▄▄▃▃▅▅▅█▃▄▆▆▇▇▄▇█▃▅▁▆▄▂▄▅▅▆▅▇▄▅▅▅▅</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>▂▂▃▅█▄▇▃▅▃▅▂▇▃▂▅▆▁▇▅▁▄▅▁▂▄▄▅▂▅▆▆▆▄▂▅▄▇█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.91572</td></tr><tr><td>eval/rougeL</td><td>0.14686</td></tr><tr><td>eval/runtime</td><td>23.6244</td></tr><tr><td>eval/samples_per_second</td><td>6.265</td></tr><tr><td>eval/steps_per_second</td><td>3.132</td></tr><tr><td>total_flos</td><td>23459936509152.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>5.29441</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.2905</td></tr><tr><td>train_loss</td><td>2.66787</td></tr><tr><td>train_runtime</td><td>234.5837</td></tr><tr><td>train_samples_per_second</td><td>5.644</td></tr><tr><td>train_steps_per_second</td><td>2.822</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_3</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/g0d8m4bg' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/g0d8m4bg</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_091006-g0d8m4bg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:15:56,483] Trial 3 finished with value: 0.14685844649079938 and parameters: {'learning_rate': 1.1715937392307063e-06, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.054671027934327966, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0.27656227050693505}. Best is trial 0 with value: 0.28420393001275346.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_091556-xa98dxlj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xa98dxlj' target=\"_blank\">hparam_trial_4</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xa98dxlj' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xa98dxlj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>2.282400</td>\n",
       "      <td>2.896617</td>\n",
       "      <td>0.146858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 331 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▂▅▄▂▃▁▂▄▅▆▄▂▅▂▂▅▄▃█▄▄▄▄▃▁▁▅▃▄▃▄▄▄</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▅▃▄▆▄▅▆▅▅▄▄▂▅▂▆▆▄▆▄▂▆▂▃▄▄▁▆▇▃▅▅█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.89662</td></tr><tr><td>eval/rougeL</td><td>0.14686</td></tr><tr><td>eval/runtime</td><td>23.5076</td></tr><tr><td>eval/samples_per_second</td><td>6.296</td></tr><tr><td>eval/steps_per_second</td><td>3.148</td></tr><tr><td>total_flos</td><td>23655330139584.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>4.96036</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.2824</td></tr><tr><td>train_loss</td><td>2.65688</td></tr><tr><td>train_runtime</td><td>234.6889</td></tr><tr><td>train_samples_per_second</td><td>5.642</td></tr><tr><td>train_steps_per_second</td><td>1.41</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_4</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xa98dxlj' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xa98dxlj</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_091556-xa98dxlj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:21:36,568] Trial 4 finished with value: 0.14685844649079938 and parameters: {'learning_rate': 1.5030900645056814e-06, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 2, 'weight_decay': 0.08287375091519295, 'lora_r': 16, 'lora_alpha': 16, 'lora_dropout': 0.2960660809801552}. Best is trial 0 with value: 0.28420393001275346.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_092136-uywzt8fz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/uywzt8fz' target=\"_blank\">hparam_trial_5</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/uywzt8fz' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/uywzt8fz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>1.176700</td>\n",
       "      <td>1.365281</td>\n",
       "      <td>0.477004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▂▁▂▃▃▄▂▃▄▃▅▅▄▇▅▄▇█▆▁▆▃▂▇▃▄█▄▃▂▁▂█▅▅▄▂▅█</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▆▅▅▅▅▆▅▃▄▄▅▃▅▃▂▂▅▃▃▂▃▂▂▃▃▃▃▃▁▃▃▃▂▂▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.36528</td></tr><tr><td>eval/rougeL</td><td>0.477</td></tr><tr><td>eval/runtime</td><td>23.6109</td></tr><tr><td>eval/samples_per_second</td><td>6.268</td></tr><tr><td>eval/steps_per_second</td><td>3.134</td></tr><tr><td>total_flos</td><td>23459936509152.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>13.58626</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1767</td></tr><tr><td>train_loss</td><td>1.59343</td></tr><tr><td>train_runtime</td><td>233.9936</td></tr><tr><td>train_samples_per_second</td><td>5.658</td></tr><tr><td>train_steps_per_second</td><td>2.829</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_5</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/uywzt8fz' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/uywzt8fz</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_092136-uywzt8fz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:27:16,317] Trial 5 finished with value: 0.47700376928318106 and parameters: {'learning_rate': 3.50339849115869e-05, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.07712703466859458, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0.01906750508580709}. Best is trial 5 with value: 0.47700376928318106.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_092716-0rhvysys</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0rhvysys' target=\"_blank\">hparam_trial_6</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0rhvysys' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0rhvysys</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 03:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:32:05,189] Trial 6 pruned. Trial was pruned at step 166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▂▁█▄▂▄▁▅▇█▃▆▇▅▃▄</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>▃▅▅▅▄▂▃▆▄▁▂▃▁█▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.03688</td></tr><tr><td>eval/rougeL</td><td>0.11835</td></tr><tr><td>eval/runtime</td><td>18.2387</td></tr><tr><td>eval/samples_per_second</td><td>8.115</td></tr><tr><td>eval/steps_per_second</td><td>2.029</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>166</td></tr><tr><td>train/grad_norm</td><td>2.44002</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.3579</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_6</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0rhvysys' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0rhvysys</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_092716-0rhvysys/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_093205-dc0h30zz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/dc0h30zz' target=\"_blank\">hparam_trial_7</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/dc0h30zz' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/dc0h30zz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:37:18,977] Trial 7 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃▃▃▄▃▃▃▅▆▄▄▄▅▂▃▅▇▆▃▄▇▂▄█▅▄▅▃▁▃▅▄▃▅▄▂▃▄▄▄</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>▇▃▂▅█▄▆▅▅▆▇▃▅▃▄▃▇▃▃▅▆▁▇▄▁▅▁▂▃▄▂▆▅▆▆▂▄▅▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.81325</td></tr><tr><td>eval/rougeL</td><td>0.15787</td></tr><tr><td>eval/runtime</td><td>23.0612</td></tr><tr><td>eval/samples_per_second</td><td>6.418</td></tr><tr><td>eval/steps_per_second</td><td>3.209</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>12.84392</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.2155</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_7</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/dc0h30zz' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/dc0h30zz</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_093205-dc0h30zz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_093718-p3x6eor2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p3x6eor2' target=\"_blank\">hparam_trial_8</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p3x6eor2' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p3x6eor2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 04:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.840200</td>\n",
       "      <td>0.849291</td>\n",
       "      <td>0.625078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▂▂▂▁▂▂▃▃▃▃▅▄▆▆▄▅▃▇▆▅▅▄▄▄█▂▂▁▆▅▄▄▄▂█▆▆</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▅▅█▄▅▅▄▅▄▄▃▃▃▂▄▂▂▁▂▁▄▃▂▁▃▁▃▂▂▂▁▂▂▂▃▃▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.84929</td></tr><tr><td>eval/rougeL</td><td>0.62508</td></tr><tr><td>eval/runtime</td><td>24.9224</td></tr><tr><td>eval/samples_per_second</td><td>5.938</td></tr><tr><td>eval/steps_per_second</td><td>2.969</td></tr><tr><td>total_flos</td><td>23655330139584.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>12.12008</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8402</td></tr><tr><td>train_loss</td><td>1.21616</td></tr><tr><td>train_runtime</td><td>243.2274</td></tr><tr><td>train_samples_per_second</td><td>5.443</td></tr><tr><td>train_steps_per_second</td><td>2.722</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_8</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p3x6eor2' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p3x6eor2</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_093718-p3x6eor2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:43:12,173] Trial 8 finished with value: 0.625078177651707 and parameters: {'learning_rate': 7.234279845665421e-05, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.08925589984899779, 'lora_r': 16, 'lora_alpha': 8, 'lora_dropout': 0.1281323365878769}. Best is trial 8 with value: 0.625078177651707.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_094312-3tphd0pf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3tphd0pf' target=\"_blank\">hparam_trial_9</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3tphd0pf' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3tphd0pf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:48:37,969] Trial 9 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▂▃▂▃▃▂▂▃▂▃▃▄▅▄▁▆▄▆▁▄▃▂▃▅▄█▂▁▂▆▃▃▄▃▃█▆</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▆█▄▅▅▄▄▃▃▄▁▄▂▃▃▃▂▁▃▂▂▂▁▂▂▂▁▂▁▂▂▂▂▃▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.94476</td></tr><tr><td>eval/rougeL</td><td>0.60895</td></tr><tr><td>eval/runtime</td><td>25.5849</td></tr><tr><td>eval/samples_per_second</td><td>5.785</td></tr><tr><td>eval/steps_per_second</td><td>2.892</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>23.66553</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.9581</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_9</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3tphd0pf' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3tphd0pf</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_094312-3tphd0pf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_094837-ooqoojh1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ooqoojh1' target=\"_blank\">hparam_trial_10</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ooqoojh1' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ooqoojh1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [83/83 03:09, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:53:18,188] Trial 10 pruned. Trial was pruned at step 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▃▆▁▅▆▄▅█</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▃▃▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.14739</td></tr><tr><td>eval/rougeL</td><td>0.56187</td></tr><tr><td>eval/runtime</td><td>17.781</td></tr><tr><td>eval/samples_per_second</td><td>8.323</td></tr><tr><td>eval/steps_per_second</td><td>2.081</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>83</td></tr><tr><td>train/grad_norm</td><td>6.20321</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.3201</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_10</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ooqoojh1' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ooqoojh1</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_094837-ooqoojh1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_095318-k9zh94at</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/k9zh94at' target=\"_blank\">hparam_trial_11</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/k9zh94at' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/k9zh94at</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 09:58:37,465] Trial 11 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▁ ▂▂▃▄▂▃▄▅▅▄▆▄▇▅▇▅▅▆▂▂▂▇▆▃▄▅▇▂▁▃▇▆▅▂▆██</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▄▅█▅▅▄▆▃▃▃▄▂▂▂▁▄▃▄▁▃▂▂▁▃▃▁▂▂▁▂▁▃▂▂▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.51672</td></tr><tr><td>eval/rougeL</td><td>0.4655</td></tr><tr><td>eval/runtime</td><td>25.3268</td></tr><tr><td>eval/samples_per_second</td><td>5.844</td></tr><tr><td>eval/steps_per_second</td><td>2.922</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>17.81431</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2522</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_11</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/k9zh94at' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/k9zh94at</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_095318-k9zh94at/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_095837-nqelulv0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/nqelulv0' target=\"_blank\">hparam_trial_12</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/nqelulv0' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/nqelulv0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 04:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.667700</td>\n",
       "      <td>0.687185</td>\n",
       "      <td>0.691592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▁▂▂▂▁▂▃▃▃▃▄▃▅▃▆▆▃▄▂▄▁▅▂▄▃▂▂▆▄▄▃▂▁█▆▇▆</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▅▄▃▄▄▃▄▄▃▃▃▄▁▄▂▁▃▁▃▂▂▂▂▂▃▂▂▂▁▂▂▂▂▂▃▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.68719</td></tr><tr><td>eval/rougeL</td><td>0.69159</td></tr><tr><td>eval/runtime</td><td>25.34</td></tr><tr><td>eval/samples_per_second</td><td>5.841</td></tr><tr><td>eval/steps_per_second</td><td>2.92</td></tr><tr><td>total_flos</td><td>23655330139584.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>12.76628</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6677</td></tr><tr><td>train_loss</td><td>1.07684</td></tr><tr><td>train_runtime</td><td>249.6166</td></tr><tr><td>train_samples_per_second</td><td>5.304</td></tr><tr><td>train_steps_per_second</td><td>2.652</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_12</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/nqelulv0' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/nqelulv0</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_095837-nqelulv0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:04:38,459] Trial 12 finished with value: 0.6915921386509621 and parameters: {'learning_rate': 9.653752916643676e-05, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.07569703666274985, 'lora_r': 16, 'lora_alpha': 8, 'lora_dropout': 0.08804517663760333}. Best is trial 12 with value: 0.6915921386509621.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_100438-1jruevch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/1jruevch' target=\"_blank\">hparam_trial_13</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/1jruevch' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/1jruevch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:09:58,455] Trial 13 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▂▂▂▂▂▂▄▃▃▃▄▃▅▅▄▆▆▆▇▃▅▅▂▂▅▄█▂▁▁▆▅▂▄▃█▅</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▅▅▅▆█▄▄▄▃▃▃▂▄▂▂▃▂▁▃▃▂▂▁▂▁▃▂▂▁▁▂▂▂▂▂▂▂▂▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.67477</td></tr><tr><td>eval/rougeL</td><td>0.68407</td></tr><tr><td>eval/runtime</td><td>24.2487</td></tr><tr><td>eval/samples_per_second</td><td>6.103</td></tr><tr><td>eval/steps_per_second</td><td>3.052</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>14.71365</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.64</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_13</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/1jruevch' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/1jruevch</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_100438-1jruevch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_100958-8vgcmeap</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8vgcmeap' target=\"_blank\">hparam_trial_14</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8vgcmeap' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8vgcmeap</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 03:25, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:15:16,327] Trial 14 pruned. Trial was pruned at step 166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▁▁▁█▃▃▆▄▅▃▂▄▂▃▄▇</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>▇█▇▇▆▄▄▆▄▂▃▄▁▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.84643</td></tr><tr><td>eval/rougeL</td><td>0.36919</td></tr><tr><td>eval/runtime</td><td>24.1479</td></tr><tr><td>eval/samples_per_second</td><td>6.129</td></tr><tr><td>eval/steps_per_second</td><td>3.064</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>166</td></tr><tr><td>train/grad_norm</td><td>3.54781</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.0427</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_14</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8vgcmeap' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8vgcmeap</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_100958-8vgcmeap/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_101516-m5m86nfl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/m5m86nfl' target=\"_blank\">hparam_trial_15</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/m5m86nfl' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/m5m86nfl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:20:45,804] Trial 15 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▃▃▂▃▁▃▄▄ ▃▂▅▃▆▆▄▆█▅▅▄▆▅▂▃▅▅▆▃▆▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▇▅▆█▆▇█▆▇▅▆▃▆▃▇▇▄▆▄▂▆▂▄▅▃▁▆▆▃▅▅█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.33735</td></tr><tr><td>eval/rougeL</td><td>0.30188</td></tr><tr><td>eval/runtime</td><td>24.1756</td></tr><tr><td>eval/samples_per_second</td><td>6.122</td></tr><tr><td>eval/steps_per_second</td><td>3.061</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>4.02642</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7631</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_15</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/m5m86nfl' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/m5m86nfl</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_101516-m5m86nfl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_102045-kro14d3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/kro14d3n' target=\"_blank\">hparam_trial_16</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/kro14d3n' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/kro14d3n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 04:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.492810</td>\n",
       "      <td>0.700363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▃▂▃▃▃▃▃▃▄▃▄▄▆▄▃▆▅▇▇▄▅▅▃▂▅▄▄█▄▃▆▄▄▁▄▂▂▆▇▆</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▅▇▄▄▄▃▄▄▃▃▂▃▃▃▂▁▂▃▂▁▃▂▂▁▂▁▃▂▂▂▁▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.49281</td></tr><tr><td>eval/rougeL</td><td>0.70036</td></tr><tr><td>eval/runtime</td><td>25.4701</td></tr><tr><td>eval/samples_per_second</td><td>5.811</td></tr><tr><td>eval/steps_per_second</td><td>2.905</td></tr><tr><td>total_flos</td><td>23655330139584.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>26.73811</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4586</td></tr><tr><td>train_loss</td><td>0.90399</td></tr><tr><td>train_runtime</td><td>245.3852</td></tr><tr><td>train_samples_per_second</td><td>5.396</td></tr><tr><td>train_steps_per_second</td><td>2.698</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_16</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/kro14d3n' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/kro14d3n</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_102045-kro14d3n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:26:44,748] Trial 16 finished with value: 0.700363424995778 and parameters: {'learning_rate': 6.593100555844184e-05, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.042558946436382895, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1987551295450799}. Best is trial 16 with value: 0.700363424995778.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_102644-26t19px9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/26t19px9' target=\"_blank\">hparam_trial_17</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/26t19px9' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/26t19px9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:32:05,841] Trial 17 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▂▃▂▂▃▃▃▃▂▃▃▃▄▅▄▃▇▄▆█▅▁▅▃▂▆▅▅▄█▂▁█▆▅▂▄▇██</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>▅█▄▅▅▅▄▅▅▃▄▁▄▂▁▃▃▄▂▁▃▂▂▁▂▁▃▂▃▁▂▂▂▂▁▂▁▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.21358</td></tr><tr><td>eval/rougeL</td><td>0.51352</td></tr><tr><td>eval/runtime</td><td>23.7118</td></tr><tr><td>eval/samples_per_second</td><td>6.242</td></tr><tr><td>eval/steps_per_second</td><td>3.121</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>59.9896</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0797</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_17</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/26t19px9' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/26t19px9</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_102644-26t19px9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_103205-pd8swjfw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/pd8swjfw' target=\"_blank\">hparam_trial_18</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/pd8swjfw' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/pd8swjfw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 03:04, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:36:39,084] Trial 18 pruned. Trial was pruned at step 166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▄▁▆▆▄▄▃▄██▄▂▅▆▄▆</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>▆█▇▇▆▄▄▇▄▁▃▃▁█▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.59606</td></tr><tr><td>eval/rougeL</td><td>0.17859</td></tr><tr><td>eval/runtime</td><td>18.8332</td></tr><tr><td>eval/samples_per_second</td><td>7.858</td></tr><tr><td>eval/steps_per_second</td><td>1.965</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>166</td></tr><tr><td>train/grad_norm</td><td>7.34823</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.9044</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_18</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/pd8swjfw' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/pd8swjfw</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_103205-pd8swjfw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_103639-zbvo27q2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/zbvo27q2' target=\"_blank\">hparam_trial_19</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/zbvo27q2' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/zbvo27q2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 03:29, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:41:46,198] Trial 19 pruned. Trial was pruned at step 166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃▂▃▃▁▁▃▃▃▃▃▄▁▄▅█</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>██▆▆▅▄▃▄▃▂▃▃▁▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.02506</td></tr><tr><td>eval/rougeL</td><td>0.58351</td></tr><tr><td>eval/runtime</td><td>24.5861</td></tr><tr><td>eval/samples_per_second</td><td>6.02</td></tr><tr><td>eval/steps_per_second</td><td>3.01</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>166</td></tr><tr><td>train/grad_norm</td><td>11.82874</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2372</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_19</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/zbvo27q2' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/zbvo27q2</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_103639-zbvo27q2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_104146-79twclft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/79twclft' target=\"_blank\">hparam_trial_20</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/79twclft' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/79twclft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:47:11,942] Trial 20 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃▂▃▃▂▃▃▃▂▂▄▄▆▆▃▃▆▇▇▄▅▄▂▅▄▃▄▇▃▃▂▁▆▅▃▃█▇▆▇</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>▅▅▆█▅▅▄▃▅▃▂▅▂▁▄▂▄▃▂▃▁▃▃▂▃▃▃▂▁▁▂▃▂▂▂▃▂▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89735</td></tr><tr><td>eval/rougeL</td><td>0.64651</td></tr><tr><td>eval/runtime</td><td>24.5577</td></tr><tr><td>eval/samples_per_second</td><td>6.027</td></tr><tr><td>eval/steps_per_second</td><td>3.013</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>55.63017</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_20</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/79twclft' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/79twclft</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_104146-79twclft/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_104711-w09gq9vm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/w09gq9vm' target=\"_blank\">hparam_trial_21</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/w09gq9vm' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/w09gq9vm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:52:30,519] Trial 21 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▂▂▃▂▃▂▃▅▄▃▆▆▅▃▇▇▆▅▄▃▂▆▃▄▄█▂▂▁▅▄▃▄▂█▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▆█▄▅▄▅▄▃▄▃▃▂▁▃▃▃▁▂▂▁▃▁▂▃▂▂▁▂▂▂▂▂▂▁▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.84533</td></tr><tr><td>eval/rougeL</td><td>0.629</td></tr><tr><td>eval/runtime</td><td>23.7762</td></tr><tr><td>eval/samples_per_second</td><td>6.225</td></tr><tr><td>eval/steps_per_second</td><td>3.112</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>12.33494</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8334</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_21</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/w09gq9vm' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/w09gq9vm</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_104711-w09gq9vm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_105230-mhubtko1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mhubtko1' target=\"_blank\">hparam_trial_22</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mhubtko1' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mhubtko1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 10:57:48,266] Trial 22 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▃▂▂▂▃▂▂▃▃▅▄▆▅▁▄▃▇▆▂▅▄▂▅▂▄█▂▂▂▁▁▆▅▃█▇▇▆</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▅█▄▄▅▄▅▄▃▃▄▂▄▂▁▃▃▂▁▄▃▂▂▃▁▃▂▁▂▁▂▂▃▃▂▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.89273</td></tr><tr><td>eval/rougeL</td><td>0.61744</td></tr><tr><td>eval/runtime</td><td>24.4341</td></tr><tr><td>eval/samples_per_second</td><td>6.057</td></tr><tr><td>eval/steps_per_second</td><td>3.029</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>11.63495</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8665</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_22</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mhubtko1' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mhubtko1</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_105230-mhubtko1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_105748-xxz76oy8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xxz76oy8' target=\"_blank\">hparam_trial_23</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xxz76oy8' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xxz76oy8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:03:11,152] Trial 23 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▂▃▃▃▂▂▂▃▃▃▃▄▄▅▃▆▁▅▄█▆▅▅▃▄▂▄█▂▃▁▇▅▃▄▂▃█▇</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▆▄▅▅▄▅▃▃▃▄▃▅▂▂▁▄▃▄▃▂▃▂▃▂▃▃▂▁▁▃▂▂▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.07127</td></tr><tr><td>eval/rougeL</td><td>0.54288</td></tr><tr><td>eval/runtime</td><td>24.0894</td></tr><tr><td>eval/samples_per_second</td><td>6.144</td></tr><tr><td>eval/steps_per_second</td><td>3.072</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>22.92767</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0191</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_23</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xxz76oy8' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/xxz76oy8</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_105748-xxz76oy8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_110311-hm48s5pr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/hm48s5pr' target=\"_blank\">hparam_trial_24</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/hm48s5pr' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/hm48s5pr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:08:29,634] Trial 24 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▂▂▂▃▂▃▃▂▃▃▃▄▄▃▅▄▆▅▅▅▃▅▄▅▄▇▂▂▃▁▇▅▄▃▅▄█▇▆</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▆█▄▅▅▅▅▃▃▃▄▄▃▂▁▃▃▄▄▃▂▂▂▃▃▃▃▂▁▁▃▂▂▃▄▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.15395</td></tr><tr><td>eval/rougeL</td><td>0.53136</td></tr><tr><td>eval/runtime</td><td>24.9074</td></tr><tr><td>eval/samples_per_second</td><td>5.942</td></tr><tr><td>eval/steps_per_second</td><td>2.971</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>10.20439</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0454</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_24</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/hm48s5pr' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/hm48s5pr</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_110311-hm48s5pr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_110829-b275dxka</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/b275dxka' target=\"_blank\">hparam_trial_25</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/b275dxka' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/b275dxka</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 04:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.426198</td>\n",
       "      <td>0.722275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▃▃▁▃▃▃▃▄▃▂▃▄▃▅▃▄▇▄▆▇▃▆█▇▁▁▄▂▃█▄▃▃▆▄▁█▆▇▆</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▃▃▃▂▂▂▃▂▁▂▁▂▂▂▂▁▂▁▂▂▁▂▂▁▂▁▂▁▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.4262</td></tr><tr><td>eval/rougeL</td><td>0.72228</td></tr><tr><td>eval/runtime</td><td>24.5796</td></tr><tr><td>eval/samples_per_second</td><td>6.021</td></tr><tr><td>eval/steps_per_second</td><td>3.011</td></tr><tr><td>total_flos</td><td>23655330139584.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>26.72816</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3883</td></tr><tr><td>train_loss</td><td>0.78145</td></tr><tr><td>train_runtime</td><td>243.8758</td></tr><tr><td>train_samples_per_second</td><td>5.429</td></tr><tr><td>train_steps_per_second</td><td>2.714</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_25</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/b275dxka' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/b275dxka</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_110829-b275dxka/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:14:17,186] Trial 25 finished with value: 0.7222753035253036 and parameters: {'learning_rate': 9.581302406749229e-05, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.06651142424918541, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.13983398787788434}. Best is trial 25 with value: 0.7222753035253036.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_111417-ut234tgj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ut234tgj' target=\"_blank\">hparam_trial_26</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ut234tgj' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ut234tgj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.460200</td>\n",
       "      <td>0.508710</td>\n",
       "      <td>0.701283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 331 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▁▂▃▁▃▁▄▂▆▃▇▄▇▂▅▆▆▄▆▄▂█▇▃▂▃▄▄▇▁█▇▇</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▄▄▃▃▂▃▁▃▁▂▃▂▂▂▁▂▂▂▂▂▁▂▁▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.50871</td></tr><tr><td>eval/rougeL</td><td>0.70128</td></tr><tr><td>eval/runtime</td><td>17.4197</td></tr><tr><td>eval/samples_per_second</td><td>8.496</td></tr><tr><td>eval/steps_per_second</td><td>2.124</td></tr><tr><td>total_flos</td><td>26495539862400.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>18.32772</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4602</td></tr><tr><td>train_loss</td><td>0.97414</td></tr><tr><td>train_runtime</td><td>207.6322</td></tr><tr><td>train_samples_per_second</td><td>6.377</td></tr><tr><td>train_steps_per_second</td><td>1.594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_26</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ut234tgj' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ut234tgj</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_111417-ut234tgj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:19:17,923] Trial 26 finished with value: 0.701282906613789 and parameters: {'learning_rate': 9.328221965821797e-05, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 1, 'weight_decay': 0.06536815457058985, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.049303095757850704}. Best is trial 25 with value: 0.7222753035253036.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_111917-2jbv6ta0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/2jbv6ta0' target=\"_blank\">hparam_trial_27</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/2jbv6ta0' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/2jbv6ta0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:24:07,714] Trial 27 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▄▁▃▂▂▂▄▂▄▂▄▁▃▄▄▃▆▃▃▆▆▂▂▄▄▃█▃▆▆▅</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▅▄▅▃▄▂▄▁▃▃▂▄▂▁▃▂▂▃▂▁▃▂▂▃▂▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.99683</td></tr><tr><td>eval/rougeL</td><td>0.59716</td></tr><tr><td>eval/runtime</td><td>17.7962</td></tr><tr><td>eval/samples_per_second</td><td>8.316</td></tr><tr><td>eval/steps_per_second</td><td>2.079</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>14.65456</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8647</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_27</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/2jbv6ta0' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/2jbv6ta0</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_111917-2jbv6ta0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_112407-4m0hl34q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4m0hl34q' target=\"_blank\">hparam_trial_28</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4m0hl34q' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4m0hl34q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [83/83 03:08, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:28:59,794] Trial 28 pruned. Trial was pruned at step 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▄█▁▆▃▃▄▆</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▇▄▃▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.56871</td></tr><tr><td>eval/rougeL</td><td>0.39408</td></tr><tr><td>eval/runtime</td><td>18.6733</td></tr><tr><td>eval/samples_per_second</td><td>7.926</td></tr><tr><td>eval/steps_per_second</td><td>1.981</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>83</td></tr><tr><td>train/grad_norm</td><td>10.46507</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6933</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_28</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4m0hl34q' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4m0hl34q</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_112407-4m0hl34q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_112859-jf34qoox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jf34qoox' target=\"_blank\">hparam_trial_29</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jf34qoox' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jf34qoox</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 03:05, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:33:43,138] Trial 29 pruned. Trial was pruned at step 166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃▁█▇▃▂▃▆█▇▂▂▃▇▃▆</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>▆▇▇▇▆▃▄▇▄▁▃▃▁█▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.6317</td></tr><tr><td>eval/rougeL</td><td>0.17135</td></tr><tr><td>eval/runtime</td><td>17.5033</td></tr><tr><td>eval/samples_per_second</td><td>8.456</td></tr><tr><td>eval/steps_per_second</td><td>2.114</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>166</td></tr><tr><td>train/grad_norm</td><td>7.16964</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.9416</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_29</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jf34qoox' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jf34qoox</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_112859-jf34qoox/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_113343-ilaz58or</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ilaz58or' target=\"_blank\">hparam_trial_30</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ilaz58or' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ilaz58or</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:38:29,966] Trial 30 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▄█▂▄▃▃▂▅▃▇▂▄▁▃▄▄▇▇▄▃▄▅▃▃▂▅▅▅▃█▅▄</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▆▄▆▆▅▇▇▅▆▄▅▂▆▂▆▆▃▆▃▂▅▂▃▄▄▁▇▇▃▅▄█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.6794</td></tr><tr><td>eval/rougeL</td><td>0.16403</td></tr><tr><td>eval/runtime</td><td>19.106</td></tr><tr><td>eval/samples_per_second</td><td>7.746</td></tr><tr><td>eval/steps_per_second</td><td>1.937</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>18.04598</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.1813</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_30</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ilaz58or' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ilaz58or</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_113343-ilaz58or/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_113829-8n5h8j84</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8n5h8j84' target=\"_blank\">hparam_trial_31</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8n5h8j84' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8n5h8j84</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='662' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 04:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.425340</td>\n",
       "      <td>0.729011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 662 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▃▂▂▂▃▂▂▃▃▄▅▃▃▅▅▃▅▃▅▅▃▄▃▃▁▁▃▂▆▁▂▃▃▃▁▃█▅▇▅</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▄▃▃▄▃▃▂▂▂▃▁▂▁▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▂▂▂▂▁▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.42534</td></tr><tr><td>eval/rougeL</td><td>0.72901</td></tr><tr><td>eval/runtime</td><td>25.8509</td></tr><tr><td>eval/samples_per_second</td><td>5.725</td></tr><tr><td>eval/steps_per_second</td><td>2.863</td></tr><tr><td>total_flos</td><td>23655330139584.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>26.29254</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3774</td></tr><tr><td>train_loss</td><td>0.77696</td></tr><tr><td>train_runtime</td><td>248.4792</td></tr><tr><td>train_samples_per_second</td><td>5.328</td></tr><tr><td>train_steps_per_second</td><td>2.664</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_31</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8n5h8j84' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8n5h8j84</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_113829-8n5h8j84/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:44:26,370] Trial 31 finished with value: 0.7290111782758841 and parameters: {'learning_rate': 9.596461243144801e-05, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.07115933746212984, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.054778160858588026}. Best is trial 31 with value: 0.7290111782758841.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_114426-jl5wwubu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jl5wwubu' target=\"_blank\">hparam_trial_32</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jl5wwubu' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jl5wwubu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.616216</td>\n",
       "      <td>0.714602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 331 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▁▂▆▁▃▁▃▂▅▃▆▃▆▁▄▅▅▄▇▄▂█▇▃▂▃▅▄▇▂█▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▄▄▃▄▃▃▂▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▁▁▃▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.61622</td></tr><tr><td>eval/rougeL</td><td>0.7146</td></tr><tr><td>eval/runtime</td><td>17.6185</td></tr><tr><td>eval/samples_per_second</td><td>8.4</td></tr><tr><td>eval/steps_per_second</td><td>2.1</td></tr><tr><td>total_flos</td><td>26495539862400.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>17.60512</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5675</td></tr><tr><td>train_loss</td><td>1.08597</td></tr><tr><td>train_runtime</td><td>209.0636</td></tr><tr><td>train_samples_per_second</td><td>6.333</td></tr><tr><td>train_steps_per_second</td><td>1.583</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_32</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jl5wwubu' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/jl5wwubu</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_114426-jl5wwubu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:49:34,781] Trial 32 finished with value: 0.7146017320649674 and parameters: {'learning_rate': 7.094134626491238e-05, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 1, 'weight_decay': 0.04267706493188495, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.003903592764484154}. Best is trial 31 with value: 0.7290111782758841.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_114934-3q9ys925</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3q9ys925' target=\"_blank\">hparam_trial_33</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3q9ys925' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3q9ys925</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:54:20,707] Trial 33 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▃▁▂▁▃▁▅▂▆▃▆▁▅▅▃▄▆▃▁██▂▁▃▄▄▇▁▇▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▄▄▃▄▃▃▁▃▁▂▃▂▃▂▁▂▂▂▂▂▁▂▁▁▂▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.59227</td></tr><tr><td>eval/rougeL</td><td>0.71213</td></tr><tr><td>eval/runtime</td><td>18.2869</td></tr><tr><td>eval/samples_per_second</td><td>8.093</td></tr><tr><td>eval/steps_per_second</td><td>2.023</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>17.31422</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5181</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_33</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3q9ys925' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/3q9ys925</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_114934-3q9ys925/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_115420-l45wfl69</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l45wfl69' target=\"_blank\">hparam_trial_34</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l45wfl69' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l45wfl69</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 11:59:16,377] Trial 34 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▃▁▂▁▃▁▅▂▆▃▅▂▅▅▄▄▆▄▂██▃▂▄▅▄▇▂█▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▆▄▄▄▃▄▃▄▂▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▂▂▃▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.68326</td></tr><tr><td>eval/rougeL</td><td>0.69078</td></tr><tr><td>eval/runtime</td><td>18.3465</td></tr><tr><td>eval/samples_per_second</td><td>8.067</td></tr><tr><td>eval/steps_per_second</td><td>2.017</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>10.74683</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6017</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_34</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l45wfl69' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/l45wfl69</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_115420-l45wfl69/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_115916-54oioe7n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/54oioe7n' target=\"_blank\">hparam_trial_35</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/54oioe7n' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/54oioe7n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:04:13,741] Trial 35 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▃▁▃▁▂▂▄▂▅▂▅▁▄▅▄▄▇▃▃██▂▂▅▅▅▇▃▇▆▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▅▄▄▃▄▂▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▂▂▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.78923</td></tr><tr><td>eval/rougeL</td><td>0.66505</td></tr><tr><td>eval/runtime</td><td>17.6276</td></tr><tr><td>eval/samples_per_second</td><td>8.396</td></tr><tr><td>eval/steps_per_second</td><td>2.099</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>14.91206</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_35</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/54oioe7n' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/54oioe7n</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_115916-54oioe7n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_120413-ssj87gil</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ssj87gil' target=\"_blank\">hparam_trial_36</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ssj87gil' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ssj87gil</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:09:12,226] Trial 36 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▃▅▂▄▂▂▃▅▄▆▁▅▁▄▄▄▅▃▄▂▅▆▂▁▂▆▄▇▂█▆▅</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇██▆▇▇▅▆▄▅▃▅▂▅▅▂▅▃▂▄▃▃▄▃▁▅▄▂▅▃▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.69672</td></tr><tr><td>eval/rougeL</td><td>0.30848</td></tr><tr><td>eval/runtime</td><td>18.7756</td></tr><tr><td>eval/samples_per_second</td><td>7.883</td></tr><tr><td>eval/steps_per_second</td><td>1.971</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>11.59246</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3955</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_36</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ssj87gil' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/ssj87gil</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_120413-ssj87gil/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_120912-7z3o8kbm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/7z3o8kbm' target=\"_blank\">hparam_trial_37</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/7z3o8kbm' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/7z3o8kbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:14:00,821] Trial 37 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▃▄▂▃▂▂▃▅▃▅▁▅▂▄▅▄▄▅▅▃▇▆▃▂▄▆▄█▄█▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇█▇▆▆▆▄▅▃▅▂▄▂▄▄▂▄▂▂▃▃▃▃▂▁▃▂▂▄▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.31968</td></tr><tr><td>eval/rougeL</td><td>0.46217</td></tr><tr><td>eval/runtime</td><td>18.8375</td></tr><tr><td>eval/samples_per_second</td><td>7.857</td></tr><tr><td>eval/steps_per_second</td><td>1.964</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>13.89428</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1104</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_37</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/7z3o8kbm' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/7z3o8kbm</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_120912-7z3o8kbm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_121400-4jmg3nhk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4jmg3nhk' target=\"_blank\">hparam_trial_38</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4jmg3nhk' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4jmg3nhk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [83/83 03:08, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:18:46,816] Trial 38 pruned. Trial was pruned at step 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▂▄▅▅▇▁█▆</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>▅▇▃▅▁▁▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.02649</td></tr><tr><td>eval/rougeL</td><td>0.11293</td></tr><tr><td>eval/runtime</td><td>17.8862</td></tr><tr><td>eval/samples_per_second</td><td>8.275</td></tr><tr><td>eval/steps_per_second</td><td>2.069</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>83</td></tr><tr><td>train/grad_norm</td><td>5.30007</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.0855</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_38</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4jmg3nhk' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/4jmg3nhk</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_121400-4jmg3nhk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_121846-qeo9xyeo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/qeo9xyeo' target=\"_blank\">hparam_trial_39</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/qeo9xyeo' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/qeo9xyeo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>0.725558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 331 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▁▂▁▃▁▄▂▅▃▅▂▅▄▄▄▄▄▂██▃▂▃▄▄▇▂█▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▄▄▃▄▃▃▁▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▂▁▂▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.60581</td></tr><tr><td>eval/rougeL</td><td>0.72556</td></tr><tr><td>eval/runtime</td><td>18.5581</td></tr><tr><td>eval/samples_per_second</td><td>7.975</td></tr><tr><td>eval/steps_per_second</td><td>1.994</td></tr><tr><td>total_flos</td><td>26167259109600.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>35.1296</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5745</td></tr><tr><td>train_loss</td><td>1.07473</td></tr><tr><td>train_runtime</td><td>215.5962</td></tr><tr><td>train_samples_per_second</td><td>6.141</td></tr><tr><td>train_steps_per_second</td><td>1.535</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_39</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/qeo9xyeo' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/qeo9xyeo</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_121846-qeo9xyeo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:23:54,106] Trial 39 finished with value: 0.7255577639768817 and parameters: {'learning_rate': 7.908136490509011e-05, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 1, 'weight_decay': 0.0827533116653657, 'lora_r': 4, 'lora_alpha': 32, 'lora_dropout': 0.0797229015275476}. Best is trial 31 with value: 0.7290111782758841.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_122354-mb2n4fmr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mb2n4fmr' target=\"_blank\">hparam_trial_40</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mb2n4fmr' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mb2n4fmr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 03:05, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:28:34,739] Trial 40 pruned. Trial was pruned at step 166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃▁▅▆▂▂▂▅▆▃▂▆▄▂▅█</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>▇█▇▇▅▄▃▅▃▂▃▃▁▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.74923</td></tr><tr><td>eval/rougeL</td><td>0.31878</td></tr><tr><td>eval/runtime</td><td>18.5529</td></tr><tr><td>eval/samples_per_second</td><td>7.977</td></tr><tr><td>eval/steps_per_second</td><td>1.994</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>166</td></tr><tr><td>train/grad_norm</td><td>18.05854</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.0111</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_40</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mb2n4fmr' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/mb2n4fmr</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_122354-mb2n4fmr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_122834-0geuyld5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0geuyld5' target=\"_blank\">hparam_trial_41</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0geuyld5' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0geuyld5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:33:07,432] Trial 41 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▁▂▁▃▁▄▂▅▃▅▂▅▅▄▄▄▄▁██▃▂▃▄▄▇▂█▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▄▄▃▄▃▃▁▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▂▁▂▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.60676</td></tr><tr><td>eval/rougeL</td><td>0.71788</td></tr><tr><td>eval/runtime</td><td>18.5042</td></tr><tr><td>eval/samples_per_second</td><td>7.998</td></tr><tr><td>eval/steps_per_second</td><td>2</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>36.21384</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5648</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_41</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0geuyld5' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/0geuyld5</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_122834-0geuyld5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_123307-s8yrkcqh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/s8yrkcqh' target=\"_blank\">hparam_trial_42</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/s8yrkcqh' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/s8yrkcqh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='331' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>0.590708</td>\n",
       "      <td>0.720112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:497: UserWarning: The reported value is ignored because this `step` 331 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/rougeL</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▁▂▁▃▁▄▂▅▄▅▂▅▅▄▄▅▄▁██▃▂▃▄▄▇▂█▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▅▄▄▄▃▄▃▃▁▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▁▁▂▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.59071</td></tr><tr><td>eval/rougeL</td><td>0.72011</td></tr><tr><td>eval/runtime</td><td>18.6577</td></tr><tr><td>eval/samples_per_second</td><td>7.932</td></tr><tr><td>eval/steps_per_second</td><td>1.983</td></tr><tr><td>total_flos</td><td>26167259109600.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>34.77969</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5513</td></tr><tr><td>train_loss</td><td>1.06083</td></tr><tr><td>train_runtime</td><td>220.6765</td></tr><tr><td>train_samples_per_second</td><td>6</td></tr><tr><td>train_steps_per_second</td><td>1.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_42</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/s8yrkcqh' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/s8yrkcqh</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_123307-s8yrkcqh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:38:15,375] Trial 42 finished with value: 0.7201117443764503 and parameters: {'learning_rate': 8.085332777225086e-05, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 1, 'weight_decay': 0.07441542829839998, 'lora_r': 4, 'lora_alpha': 32, 'lora_dropout': 0.04559102042483379}. Best is trial 31 with value: 0.7290111782758841.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_123815-fisdc1e7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/fisdc1e7' target=\"_blank\">hparam_trial_43</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/fisdc1e7' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/fisdc1e7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:43:04,595] Trial 43 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▃▁▂▁▂▂▄▂▆▃▄▁▄▅▅▄▆▃▄▇█▂▂▄▅▄▇▃▇▆▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▅▃▄▃▄▂▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▂▂▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.73073</td></tr><tr><td>eval/rougeL</td><td>0.69384</td></tr><tr><td>eval/runtime</td><td>18.8323</td></tr><tr><td>eval/samples_per_second</td><td>7.859</td></tr><tr><td>eval/steps_per_second</td><td>1.965</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>36.69892</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6835</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_43</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/fisdc1e7' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/fisdc1e7</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_123815-fisdc1e7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_124304-u24acpvx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/u24acpvx' target=\"_blank\">hparam_trial_44</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/u24acpvx' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/u24acpvx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:47:52,633] Trial 44 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▃▁▃▁▂▁▃▂▃▂▃▁▃▄▄▃ ▄▃▆▆▂▂▄▅▄█▄▇▆▅</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▅▄▄▃▄▂▃▁▃▃▂▄▂▂▃▂▂▃▂▁▃▂▂▃▂▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.9268</td></tr><tr><td>eval/rougeL</td><td>0.58382</td></tr><tr><td>eval/runtime</td><td>17.8752</td></tr><tr><td>eval/samples_per_second</td><td>8.28</td></tr><tr><td>eval/steps_per_second</td><td>2.07</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>29.69999</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8354</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_44</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/u24acpvx' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/u24acpvx</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_124304-u24acpvx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_124752-8p083sik</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8p083sik' target=\"_blank\">hparam_trial_45</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8p083sik' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8p083sik</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:52:42,172] Trial 45 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▃▁▂▁▂▁▃▂▆▁▄▁▄▅▄▃▅▄▄▇█▂▂▄▅▄▇▃▇▆▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▅▄▄▃▄▂▃▁▃▃▂▃▂▁▃▂▂▃▂▁▃▂▂▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.85086</td></tr><tr><td>eval/rougeL</td><td>0.65818</td></tr><tr><td>eval/runtime</td><td>19.1568</td></tr><tr><td>eval/samples_per_second</td><td>7.726</td></tr><tr><td>eval/steps_per_second</td><td>1.931</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>18.13784</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7934</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_45</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8p083sik' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8p083sik</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_124752-8p083sik/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_125242-p4uzjrtc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p4uzjrtc' target=\"_blank\">hparam_trial_46</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p4uzjrtc' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p4uzjrtc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 12:57:27,516] Trial 46 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▂▁▁▁▂▁▃▂▄▃▄▁▄▄▃▃▄▃▁▆▇▂▂▂▄▃▅▂█▅▅</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▄▄▃▄▃▃▁▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▁▂▂▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.59581</td></tr><tr><td>eval/rougeL</td><td>0.7137</td></tr><tr><td>eval/runtime</td><td>18.4344</td></tr><tr><td>eval/samples_per_second</td><td>8.028</td></tr><tr><td>eval/steps_per_second</td><td>2.007</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>33.63998</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5536</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_46</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p4uzjrtc' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/p4uzjrtc</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_125242-p4uzjrtc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_125727-o7fzm4o2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/o7fzm4o2' target=\"_blank\">hparam_trial_47</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/o7fzm4o2' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/o7fzm4o2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='663' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [662/662 03:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 13:02:45,486] Trial 47 pruned. Trial was pruned at step 662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▂▂▁▂▂▂▂▁▂▄▃▆▄▃▆▂▂▆▄▇▇▁▄▃▂▂▂▄█▁▄▁▁▆▃▄█▆▇▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▆▃▄▃▄▄▄▂▃▄▃▂▃▃▂▁▃▂▂▂▁▂▃▂▂▂▂▂▁▂▂▂▃▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.64329</td></tr><tr><td>eval/rougeL</td><td>0.7004</td></tr><tr><td>eval/runtime</td><td>24.4284</td></tr><tr><td>eval/samples_per_second</td><td>6.059</td></tr><tr><td>eval/steps_per_second</td><td>3.029</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>662</td></tr><tr><td>train/grad_norm</td><td>45.82072</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6608</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_47</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/o7fzm4o2' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/o7fzm4o2</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_125727-o7fzm4o2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_130245-8wqbggnd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8wqbggnd' target=\"_blank\">hparam_trial_48</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8wqbggnd' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8wqbggnd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 13:07:21,885] Trial 48 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/rougeL</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▃▂▂▂▃▁▅▂▅▂▆▁▄▅▄▄▅▃▃▇█▃▂▃▅▅█▂█▆▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▅▃▄▃▄▂▃▁▃▃▂▃▂▁▂▂▂▂▂▁▂▂▂▃▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.68933</td></tr><tr><td>eval/rougeL</td><td>0.69016</td></tr><tr><td>eval/runtime</td><td>17.5464</td></tr><tr><td>eval/samples_per_second</td><td>8.435</td></tr><tr><td>eval/steps_per_second</td><td>2.109</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>331</td></tr><tr><td>train/grad_norm</td><td>29.21919</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6145</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hparam_trial_48</strong> at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8wqbggnd' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/8wqbggnd</a><br> View project at: <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_130245-8wqbggnd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250517_130721-62jcb9v9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/62jcb9v9' target=\"_blank\">hparam_trial_49</a></strong> to <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/MedPixel/florence2_hparam_trial/runs/62jcb9v9' target=\"_blank\">https://wandb.ai/MedPixel/florence2_hparam_trial/runs/62jcb9v9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87947/295073416.py:75: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
      "/tmp/ipykernel_87947/295073416.py:78: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
      "/tmp/ipykernel_87947/295073416.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='332' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [331/331 03:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 13:12:26,127] Trial 49 pruned. Trial was pruned at step 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "FrozenTrial(number=31, state=TrialState.COMPLETE, values=[0.7290111782758841], datetime_start=datetime.datetime(2025, 5, 17, 11, 38, 29, 967734), datetime_complete=datetime.datetime(2025, 5, 17, 11, 44, 26, 369689), params={'learning_rate': 9.596461243144801e-05, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'weight_decay': 0.07115933746212984, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.054778160858588026}, user_attrs={}, system_attrs={'completed_rung_0': 0.7290111782758841, 'completed_rung_1': 0.7290111782758841, 'completed_rung_2': 0.7290111782758841, 'completed_rung_3': 0.7290111782758841}, intermediate_values={662: 0.7290111782758841}, distributions={'learning_rate': FloatDistribution(high=0.0001, log=True, low=1e-06, step=None), 'per_device_train_batch_size': CategoricalDistribution(choices=(2, 4)), 'gradient_accumulation_steps': CategoricalDistribution(choices=(1, 2, 4)), 'weight_decay': FloatDistribution(high=0.1, log=False, low=0.0, step=None), 'lora_r': CategoricalDistribution(choices=(4, 8, 16)), 'lora_alpha': CategoricalDistribution(choices=(8, 16, 32)), 'lora_dropout': FloatDistribution(high=0.3, log=False, low=0.0, step=None)}, trial_id=31, value=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import optuna\n",
    "import wandb\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoProcessor,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# -- 1) Setup HF login and global objects --\n",
    "load_dotenv(\"secrets.env\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "\n",
    "MODEL_NAME = \"microsoft/Florence-2-base-ft\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# Load full dataset\n",
    "raw_ds = load_dataset(\"SimulaMet-HOST/Kvasir-VQA\")['raw']\n",
    "\n",
    "# Load metrics\n",
    "bleu, meteor, rouge = map(evaluate.load, [\"bleu\", \"meteor\", \"rouge\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # decode predictions and labels\n",
    "    preds = np.argmax(logits[0], axis=-1)\n",
    "    pred_texts = processor.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    label_ids = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)\n",
    "    label_texts = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    pred_texts = [p.strip() for p in pred_texts]\n",
    "    label_texts = [l.strip() for l in label_texts]\n",
    "    return {\"rougeL\": rouge.compute(predictions=pred_texts, references=label_texts)[\"rougeL\"]}\n",
    "\n",
    "# Callback to report metrics to Optuna and prune\n",
    "class OptunaPruningCallback(TrainerCallback):\n",
    "    def __init__(self, trial, metric_name: str):\n",
    "        self.trial = trial\n",
    "        self.metric_name = metric_name\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        score = metrics.get(self.metric_name)\n",
    "        step = state.global_step\n",
    "        self.trial.report(score, step)\n",
    "        if self.trial.should_prune():\n",
    "            raise TrialPruned(f\"Trial was pruned at step {step}\")\n",
    "        return control\n",
    "\n",
    "# Objective for Optuna\n",
    "def objective(trial):\n",
    "    # Initialize WandB\n",
    "    run_name = f\"hparam_trial_{trial.number}\"\n",
    "    wandb.init(\n",
    "        project=\"florence2_hparam_trial\",\n",
    "        name=run_name,\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    # -- 2) Sample hyperparameters --\n",
    "    lr       = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
    "    train_bs = trial.suggest_categorical(\"per_device_train_batch_size\", [2, 4])\n",
    "    grad_acc = trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4])\n",
    "    weight_decay = trial.suggest_uniform(\"weight_decay\", 0.0, 0.1)\n",
    "    lora_r      = trial.suggest_categorical(\"lora_r\", [4, 8, 16])\n",
    "    lora_alpha  = trial.suggest_categorical(\"lora_alpha\", [8, 16, 32])\n",
    "    lora_dropout= trial.suggest_uniform(\"lora_dropout\", 0.0, 0.3)\n",
    "\n",
    "    # Log hyperparameters to WandB\n",
    "    wandb.config.update({\n",
    "        \"lr\": lr,\n",
    "        \"train_bs\": train_bs,\n",
    "        \"grad_acc\": grad_acc,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"lora_r\": lora_r,\n",
    "        \"lora_alpha\": lora_alpha,\n",
    "        \"lora_dropout\": lora_dropout,\n",
    "    })\n",
    "\n",
    "    # -- 3) Prepare small train/val split (2.5% coverage) --\n",
    "    DATASET_COVERAGE = 0.025\n",
    "    SEED = 7\n",
    "    TEST_SIZE = 0.1\n",
    "    \n",
    "    if DATASET_COVERAGE < 1:\n",
    "        dataset = raw_ds.train_test_split(test_size=DATASET_COVERAGE, seed=SEED, shuffle=True)\n",
    "        dataset = dataset['test'].train_test_split(test_size=TEST_SIZE, seed=SEED)\n",
    "        train_dataset, val_dataset = dataset['train'], dataset['test']\n",
    "    else:\n",
    "        dataset = ds.train_test_split(test_size=TEST_SIZE, seed=SEED)\n",
    "        train_dataset, val_dataset = dataset['train'], dataset['test']\n",
    "    \n",
    "    # -- 4) Load model, processor, and apply LoRA --\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "    peft_config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"lm_head\", \"fc2\"],\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        inference_mode=False\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # -- 5) Collate function --\n",
    "    def collate_fn(batch):\n",
    "        questions = [x['question'] for x in batch]\n",
    "        images = [x['image'].convert(\"RGB\") if x['image'].mode != \"RGB\" else x['image'] for x in batch]\n",
    "        answers = [x['answer'] for x in batch]\n",
    "\n",
    "        inputs = processor(text=questions, images=images, return_tensors=\"pt\", padding=True)\n",
    "        labels = processor.tokenizer(answers, return_tensors=\"pt\", padding=True).input_ids\n",
    "        labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "        inputs[\"labels\"] = labels\n",
    "        return inputs\n",
    "\n",
    "    # -- 6) Compute steps --\n",
    "    TRAIN_DATASET_SIZE = len(train_dataset)\n",
    "    NUM_EPOCHS = 1\n",
    "    effective_bs = train_bs * grad_acc\n",
    "    steps_per_epoch = math.ceil(TRAIN_DATASET_SIZE / effective_bs)\n",
    "    max_steps = steps_per_epoch * NUM_EPOCHS\n",
    "\n",
    "    # -- 7) TrainingArguments with pruning --\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=run_name,\n",
    "        per_device_train_batch_size=train_bs,\n",
    "        gradient_accumulation_steps=grad_acc,\n",
    "        per_device_eval_batch_size=train_bs,\n",
    "        eval_accumulation_steps=1,\n",
    "        max_steps=max_steps,\n",
    "        learning_rate=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        # save_steps=steps_per_epoch,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=steps_per_epoch,\n",
    "        report_to=[\"wandb\"],\n",
    "        # load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"rougeL\",\n",
    "        greater_is_better=True,\n",
    "        fp16=True,\n",
    "        remove_unused_columns=False,\n",
    "    )\n",
    "\n",
    "    pruning_cb = OptunaPruningCallback(trial, metric_name=\"eval_rougeL\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[pruning_cb, EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    # -- 8) Train & evaluate --\n",
    "    trainer.train()\n",
    "    results = trainer.evaluate()\n",
    "    wandb.finish()\n",
    "\n",
    "    return results[\"eval_rougeL\"]\n",
    "\n",
    "# -- 9) Run Optuna study --\n",
    "pruner = SuccessiveHalvingPruner()\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=pruner,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c7a111-3b95-46df-8d08-35eb6349681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 9.596461243144801e-05,\n",
       " 'per_device_train_batch_size': 2,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'weight_decay': 0.07115933746212984,\n",
       " 'lora_r': 16,\n",
       " 'lora_alpha': 32,\n",
       " 'lora_dropout': 0.054778160858588026}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae745919-53ed-45b9-8419-f9918071922f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3991153107862002e-05"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9.596461243144801e-05/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b13bd2-97cf-4f4f-9f12-0a764a44f0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
